{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f96e86b",
   "metadata": {},
   "source": [
    "# Piano-roll experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047f686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pretty_midi\n",
    "import glob\n",
    "import collections\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.data import Dataset\n",
    "import IPython.display\n",
    "\n",
    "from tqdm import tqdm\n",
    "from music21 import converter, instrument, note, chord, stream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c08970a",
   "metadata": {},
   "source": [
    "## Usefull methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dff5128",
   "metadata": {},
   "source": [
    "### Method to create a midi file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cee521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMidi(combined_notes, fileName):\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "    \n",
    "    for combine in combined_notes:\n",
    "\n",
    "        for midi_notes in ind_to_char[combine].split('&'):\n",
    "            try:\n",
    "                new_note = note.Note(float(midi_notes))\n",
    "                new_note.offset = offset\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                output_notes.append(new_note)\n",
    "            except:\n",
    "                pass\n",
    "        offset += 0.5\n",
    "            \n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    \n",
    "    print('Saving Output file as midi....')\n",
    "    print(len(output_notes))\n",
    "\n",
    "    midi_stream.write('midi', fp=fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf56c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = []\n",
    "with (open(\"MuseData.pickle\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5751fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_notes = []\n",
    "for song in objects[0]['test']:\n",
    "    for combineNote in song:\n",
    "        notes_string = ''\n",
    "        while len(combineNote) > 3:\n",
    "            combineNote.pop(random.randrange(len(combineNote)))\n",
    "        for notes in combineNote:\n",
    "            notes_string += str(notes) + '&'\n",
    "        all_notes.append(notes_string[:-1])\n",
    "        \n",
    "for song in objects[0]['train']:\n",
    "    for combineNote in song:\n",
    "        notes_string = ''\n",
    "        while len(combineNote) > 3:\n",
    "            combineNote.pop(random.randrange(len(combineNote)))\n",
    "        for notes in combineNote:\n",
    "            notes_string += str(notes) + '&'\n",
    "        all_notes.append(notes_string[:-1])\n",
    "        \n",
    "for song in objects[0]['valid']:\n",
    "    for combineNote in song:\n",
    "        notes_string = ''\n",
    "        while len(combineNote) > 3:\n",
    "            combineNote.pop(random.randrange(len(combineNote)))\n",
    "        for notes in combineNote:\n",
    "            notes_string += str(notes) + '&'\n",
    "        all_notes.append(notes_string[:-1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d65b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa67f29",
   "metadata": {},
   "source": [
    "### create a diccionary of notes and encode the full pack of notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0a706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionary = sorted(set(item for item in all_notes))\n",
    "\n",
    "char_to_ind = {u:i for i, u in enumerate(diccionary)}\n",
    "\n",
    "ind_to_char = np.array(diccionary)\n",
    "\n",
    "encoded_text = np.array([char_to_ind[c] for c in all_notes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0bf6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(diccionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f933e691",
   "metadata": {},
   "source": [
    "## Creating batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d556aaf8",
   "metadata": {},
   "source": [
    "### calculate total num of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c57e5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 50\n",
    "\n",
    "total_num_seq = len(all_notes)//(seq_len+1)\n",
    "total_num_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db95ad2d",
   "metadata": {},
   "source": [
    "### divide the entire dataset of notes into sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016b0ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874cd9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\n",
    "\n",
    "sequences = char_dataset.batch(seq_len+1, drop_remainder=True)\n",
    "\n",
    "def create_seq_targets(seq):\n",
    "    input_txt = seq[:-1]\n",
    "    target_txt = seq[1:]\n",
    "    return input_txt, target_txt\n",
    "\n",
    "dataset = sequences.map(create_seq_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25780bf7",
   "metadata": {},
   "source": [
    "### create batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802516a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "\n",
    "buffer_size = 10000\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e0ac17",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7659bce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(diccionary)\n",
    "\n",
    "embed_dim = 128\n",
    "\n",
    "rnn_neurons = 256\n",
    "\n",
    "dropout_value = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25d16b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout,GRU\n",
    "\n",
    "from tensorflow.keras.initializers import GlorotNormal\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1118d33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_cat_loss(y_true,y_pred):\n",
    "    return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)\n",
    "\n",
    "def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim = vocab_size, output_dim = embed_dim, batch_input_shape=[batch_size, None]))\n",
    "    model.add(LSTM(rnn_neurons,\n",
    "                   return_sequences=True,\n",
    "                   stateful=True,\n",
    "                   recurrent_initializer=GlorotNormal()\n",
    "                  ))\n",
    "    model.add(Dropout(dropout_value))\n",
    "    model.add(LSTM(rnn_neurons,\n",
    "                   return_sequences=True,\n",
    "                   stateful=True,\n",
    "                   recurrent_initializer=GlorotNormal()\n",
    "                  ))\n",
    "    model.add(Dropout(dropout_value))\n",
    "    model.add(Dense(vocab_size))\n",
    "    return model\n",
    " \n",
    "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d99f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010ef247",
   "metadata": {},
   "source": [
    "## Generate note using the model without training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c908cd",
   "metadata": {},
   "source": [
    "### expecting to see something random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b995af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "\n",
    "    print(example_batch_predictions.shape, \" <=== (batch_size, sequence_length, vocab_size)\")\n",
    "\n",
    "\n",
    "example_batch_predictions\n",
    "\n",
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices\n",
    "\n",
    "# Reformat to not be a lists of lists\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
    "sampled_indices\n",
    "\n",
    "createMidi(input_example_batch[0], 'input_piano_seq.mid')\n",
    "createMidi(sampled_indices, 'sample_piano_seq.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9503c399",
   "metadata": {},
   "source": [
    "### Compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2560829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e96174",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = sparse_cat_loss, optimizer = Adam(learning_rate=0.005), metrics=['accuracy'])\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience = 10)\n",
    "\n",
    "r = model.fit(dataset, epochs = 200, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe090248",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(r.history['loss'], label='loss')\n",
    "\n",
    "plt.title('Training error on Piano model')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(r.history['accuracy'], label='accuracy')\n",
    "\n",
    "plt.title('Training accuracy on Piano model')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce245361",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'piano_gen_.h5'\n",
    "model.save(model_name ,save_format='h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55648a1f",
   "metadata": {},
   "source": [
    "## Generate music using the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbe68e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size=1)\n",
    "model.load_weights(model_name)\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "model.summary()\n",
    "\n",
    "def generate_text(model, start_seed,gen_size=100,temp=1):\n",
    "      \n",
    "    num_generate = gen_size\n",
    "    input_eval = [char_to_ind[s] for s in start_seed]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    \n",
    "    music_generated = []\n",
    "\n",
    "    temperature = temp\n",
    "\n",
    "    model.reset_states()\n",
    "\n",
    "    for i in range(num_generate):\n",
    "\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        music_generated.append(predicted_id)\n",
    "    \n",
    "    createMidi(music_generated, 'finalPiano.mid')\n",
    "\n",
    "    return 'Music generated'\n",
    "\n",
    "print(generate_text(model,all_notes[:50],gen_size=200))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
