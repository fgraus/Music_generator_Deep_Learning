{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4ce951e",
   "metadata": {},
   "source": [
    "# Classical generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c88a169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pretty_midi\n",
    "import glob\n",
    "import collections\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.data import Dataset\n",
    "import IPython.display\n",
    "\n",
    "from tqdm import tqdm\n",
    "from music21 import converter, instrument, note, chord, stream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482f1d03",
   "metadata": {},
   "source": [
    "## Usefull methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e720d990",
   "metadata": {},
   "source": [
    "### Method to create a midi file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60a615d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMidi(notes, fileName):\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "    \n",
    "    for nota in notes:\n",
    "        translated_note = ind_to_char[nota]\n",
    "        new_note = note.Note(int(translated_note.split('&')[0]))\n",
    "        new_note.offset = offset\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "        output_notes.append(new_note)\n",
    "        \n",
    "        try:\n",
    "            offset += float(translated_note.split('&')[1])\n",
    "        except:\n",
    "            offset += float(translated_note.split('&')[1].split('/')[0]) / float(translated_note.split('&')[1].split('/')[1])\n",
    "        \n",
    "    \n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    \n",
    "    print('Saving Output file as midi....')\n",
    "\n",
    "    midi_stream.write('midi', fp=fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9b587c",
   "metadata": {},
   "source": [
    "## Handle data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f60190",
   "metadata": {},
   "source": [
    "### get file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c9f3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('data/classical')\n",
    "filenames = glob.glob(str(data_dir/'*.mid*'))\n",
    "print('Number of files: ', len(filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e73d97",
   "metadata": {},
   "source": [
    "### extract all the notes from the files (TAKES A LOT OF TIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59779753",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_notes = []\n",
    "for i in tqdm(range(len(filenames))):\n",
    "    file = filenames[i]\n",
    "    midi = converter.parse(file)\n",
    "\n",
    "    flatten_notes = midi.flat.notes\n",
    "\n",
    "    for flat_note in flatten_notes:\n",
    "        if isinstance(flat_note, note.Note):\n",
    "            all_notes.append(str(flat_note.pitch.midi)+'&'+str(flat_note.duration.quarterLength))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc96affd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744dafca",
   "metadata": {},
   "source": [
    "### Plot some information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d712006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noteToFreq(note):\n",
    "    a = 440 #frequency of A (coomon value is 440Hz)\n",
    "    return (a / 32) * (2 ** ((note - 9) / 12))\n",
    "\n",
    "sinlgeNote = []\n",
    "for no in all_notes:\n",
    "    freq.append(noteToFreq(int(no.split('&')[0])))\n",
    "    \n",
    "df = pd.DataFrame(freq, columns=['Frecuency'])\n",
    "df.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ab8799",
   "metadata": {},
   "source": [
    "### create a diccionary of notes and encode the full pack of notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8aa812",
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionary = sorted(set(item for item in all_notes))\n",
    "\n",
    "char_to_ind = {u:i for i, u in enumerate(diccionary)}\n",
    "\n",
    "ind_to_char = np.array(diccionary)\n",
    "\n",
    "encoded_text = np.array([char_to_ind[c] for c in all_notes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d85fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(diccionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3864ffc",
   "metadata": {},
   "source": [
    "## Creating batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab106910",
   "metadata": {},
   "source": [
    "### calculate total num of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b834bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 50\n",
    "\n",
    "total_num_seq = len(all_notes)//(seq_len+1)\n",
    "total_num_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db59bf2",
   "metadata": {},
   "source": [
    "### divide the entire dataset of notes into sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dbbac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e247140",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\n",
    "\n",
    "sequences = char_dataset.batch(seq_len+1, drop_remainder=True)\n",
    "\n",
    "def create_seq_targets(seq):\n",
    "    input_txt = seq[:-1]\n",
    "    target_txt = seq[1:]\n",
    "    return input_txt, target_txt\n",
    "\n",
    "dataset = sequences.map(create_seq_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4173987a",
   "metadata": {},
   "source": [
    "### create batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf71d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "\n",
    "buffer_size = 10000\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f04e92",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f1cb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(diccionary)\n",
    "\n",
    "embed_dim = 128\n",
    "\n",
    "rnn_neurons = 256\n",
    "\n",
    "dropout_value = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef71ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout,GRU\n",
    "\n",
    "from tensorflow.keras.initializers import GlorotNormal\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0582174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_cat_loss(y_true,y_pred):\n",
    "    return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)\n",
    "\n",
    "def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim = vocab_size, output_dim = embed_dim, batch_input_shape=[batch_size, None]))\n",
    "    model.add(LSTM(rnn_neurons,\n",
    "                   return_sequences=True,\n",
    "                   stateful=True,\n",
    "                   recurrent_initializer=GlorotNormal()\n",
    "                  ))\n",
    "    model.add(Dropout(dropout_value))\n",
    "    model.add(LSTM(rnn_neurons,\n",
    "                   return_sequences=True,\n",
    "                   stateful=True,\n",
    "                   recurrent_initializer=GlorotNormal()\n",
    "                  ))\n",
    "    model.add(Dropout(dropout_value))\n",
    "    model.add(Dense(vocab_size))\n",
    "    return model\n",
    " \n",
    "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6d9adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded36094",
   "metadata": {},
   "source": [
    "## Generate note using the model without training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8646de66",
   "metadata": {},
   "source": [
    "### expecting to see something random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938d1748",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "\n",
    "    print(example_batch_predictions.shape, \" <=== (batch_size, sequence_length, vocab_size)\")\n",
    "\n",
    "\n",
    "example_batch_predictions\n",
    "\n",
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices\n",
    "\n",
    "# Reformat to not be a lists of lists\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
    "sampled_indices\n",
    "\n",
    "createMidi(input_example_batch[0], 'input_classical_seq.mid')\n",
    "createMidi(sampled_indices, 'sample_classical_seq.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df2313f",
   "metadata": {},
   "source": [
    "### Compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ae13c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbb9deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = sparse_cat_loss, optimizer = Adam(learning_rate=0.005), metrics=['accuracy'])\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience = 10)\n",
    "\n",
    "r = model.fit(dataset, epochs = 800, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ae4ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(r.history['loss'], label='loss')\n",
    "\n",
    "plt.title('Training error on Classical model')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(r.history['accuracy'], label='accuracy')\n",
    "\n",
    "plt.title('Training accuracy on Classical model')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993dc31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'classical_gen_.h5'\n",
    "model.save(model_name ,save_format='h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fbf3bf",
   "metadata": {},
   "source": [
    "## Generate music using the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9c99fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size=1)\n",
    "model.load_weights(model_name)\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "model.summary()\n",
    "\n",
    "def generate_text(model, start_seed,gen_size=100,temp=1):\n",
    "      \n",
    "    num_generate = gen_size\n",
    "    input_eval = [char_to_ind[s] for s in start_seed]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    \n",
    "    music_generated = []\n",
    "\n",
    "    temperature = temp\n",
    "    model.reset_states()\n",
    "\n",
    "    for i in range(num_generate):\n",
    "\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        music_generated.append(predicted_id)\n",
    "    \n",
    "    createMidi(music_generated, 'finalClassical.mid')\n",
    "        \n",
    "    return 'Music generated'\n",
    "\n",
    "print(generate_text(model,all_notes[:50],gen_size=200))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "232.844px",
    "left": "138px",
    "right": "20px",
    "top": "81px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
